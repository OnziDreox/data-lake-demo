## base properties
hoodie.upsert.shuffle.parallelism=2
hoodie.insert.shuffle.parallelism=2
hoodie.delete.shuffle.parallelism=2
hoodie.bulkinsert.shuffle.parallelism=2

## datasource properties
hoodie.datasource.hive_sync.database=datalake
hoodie.datasource.hive_sync.table=cdc_events
hoodie.datasource.hive_sync.partition_fields=customer_id,order_id
hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.MultiPartKeysValueExtractor
hoodie.datasource.hive_sync.jdbcurl=jdbc:hive2://10.0.28.106:10000
hoodie.datasource.write.recordkey.field=order_id
hoodie.datasource.write.partitionpath.field=customer_id,order_id
hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.ComplexKeyGenerator
hoodie.datasource.write.hive_style_partitioning=true
# only supported in Hudi 0.9.0+
# hoodie.datasource.write.drop.partition.columns=true

## deltastreamer properties
hoodie.deltastreamer.schemaprovider.source.schema.file=s3://bri-data-lake-demo/hudi/config/schema-msk.datalake.cdc_events.avsc
hoodie.deltastreamer.source.dfs.root=s3://bri-data-lake-demo/cdc-events/

## file properties
# 1,024 * 1,024 * 128 = 134,217,728 (128 MB)
hoodie.parquet.small.file.limit=134217728